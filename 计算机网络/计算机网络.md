# Computer Networking



## 2.Application Layer

### 2.1 Principles of Network Applications

**Network Application Architectures**

> **The two predominant architectural paradigms**
>
> - The client-server architecture 
>
> - The peer-to-peer (P2P) architecture
>
> - In a ***client-server architecture***, there is an always-on host, called the **server**
>   - the server has a fixed, well-known address, called an IP address
>   - a ***data center***, housing a large number of hosts, is often used to create apowerful virtual server.
>
> - In a ***P2P architecture***, there is minimal (or no) reliance on dedicated servers in data centers
>
>   - the application exploits direct communication between pairs of intermittently connected hosts, called ***peers*（对等方）**

***

**Processes Communicating**

>- It is not actually programs but **processes** that communicate.
>
>- Processes on two different end systems communicate with each other by **exchanging messages** across the computer network

- Client and Server Processes
- For each pair of communicating processes, we typically label one of the two processes as the **client** and the other process as the **server**
    - With the Web, a browser is a client process and a Web server is a server process. 
    - With P2P file sharing, the peer that is ***downloading the file*** is labeled as the ***client***, and the peer that is ***uploading the file*** is labeled as the ***server***.
  
- We define the client and server processes as follows
  - the process that *initiates the communication* (that is, initially contacts the other process at the beginning of the session) is labeled as the ***client***. 
  - The process that *waits to be contacted* to begin the session is the ***server***.
  

***

**The Interface Between the Process and the Computer Network**

- A process sends messages into, and receives messages from, the network through a software interface called a **socket.**

- **Addressing Processes**
  - In the Internet, the host is identified by its ***IP*** address. 
  - In addition to knowing the address of the host to which a message is destined, the sending process must also identify the receiving process running in the host. 
    - A destination **port number** serves this purpose.

- **Transport Services Available to Applications**
- When you develop an application, you must choose one of the available transport-layer protocols.
  - We can broadly classify the ***possible services*** along four dimensions: 
    - reliable data transfer, throughput, timing, and security.
  

***

**Reliable Data Transfer**

> If a protocol provides such a guaranteed data delivery service, it is said to provide **reliable data transfer.**

- When a transport protocol provides this service, the sending process can just pass its data into the socket and know with complete confidence that the data will arrive without errors at the receiving process.

**Throughput**

> The ***rate*** at which the sending process can deliver bits to the receiving process.

- Applications that have throughput requirements are said to be ***bandwidth-sensitive applications***
- ***elastic applications*** can make use of as much, or as little, throughput as happens to be available.

**Timing**

> A transport-layer protocol can also provide timing guarantees.

- An example guarantee might be that every bit that the sender pumps into the socket arrives at the receiver’s socket no more than 100 msec later

**Security**

***

**Transport Services Provided by the Internet**

> The Internet (and, more generally, TCP/IP networks) makes two transport protocols available to applications, **UDP and TCP**. 

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\image-20201009224955571.png" alt="image-20201009224955571" style="zoom:50%;" />

**TCP Services**

> The TCP service model includes a ***connection-oriented service*** and a ***reliable data transfer*** service

**Connection-oriented service.** 

> TCP has the client and server **exchange transport-layer control information** with each other before the application-level messages begin to flow. 
>
> This so-called handshaking procedure alerts the client and server, allowing them to **prepare for an onslaught of packets**.
>
> After the handshaking phase, a **TCP connection** is said to exist between the sockets of the two processes.

- The connection is a full-duplex connection in that the two processes can send messages to each other over the connection at the same time.
- When the application finishes sending messages, it must tear down the connection.

**Reliable data transfer service.** 

> The communicating processes can rely on TCP to deliver all data sent without error and in the proper order. 

**UDP Services**

> UDP is a no-frills, lightweight transport protocol, providing minimal services.

***

### 2.2The Web and HTTP

**HTTP with non-persistent connection**

- **round-trip time(RTT)**
  - the time it takes for a small packet to travel from client to server and then back to the client.
  - includes packet-propagation delays, packet-queuing delays in intermediate routers and switches, and packet-processing delays. 

- when a user clicks on a hyperlink
  - this causes the browser to initiate a TCP connection between the browser and the Web server; this
    involves a “**three-way handshake**”
  - the client sends a small TCP segment to the server, the server acknowledges and **responds with a small TCP segment**
  - finally, the client acknowledges back to the server.
- The first two parts of the three-way handshake take one RTT. 

- Thus, roughly, the total response time is two RTTs plus the transmission time at the server of the HTML file.

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\2.png" style="zoom:50%;" />

***

**HTTP with Persistent Connections**

- With persistent connections, the server leaves the TCP connection open after sending a response. Subsequent requests and responses between the same client and server can be sent over the same connection. 

***

**HTTP Message Format**

- HTTP Request Message

  ````
  GET /somedir/page.html HTTP/1.1
  Host: www.someschool.edu
  Connection: close
  User-agent: Mozilla/5.0
  Accept-language: fr
  ````

- The first line of an HTTP request message is called the **request line**; 

- the subsequent lines are called the **header lines**.

- The request line has three fields: the method field, the URL field, and the HTTP version field

- The **method field** can take on several different values, including GET, POST, HEAD, PUT, and DELETE.

  - The header line **Host**: www.someschool.edu specifies the host on which the object resides
  - By including the **Connection**: close header line, the browser is telling the server that it doesn’t want to bother with persistent connections
  - The **User-agent**: header line specifies the user agent, that is, the browser type that is making the request to the server.
  - the **Accept-language**: header indicates that the user prefers to receive a French version of the object, if such an object exists on the server; otherwise, the server should send its default version.

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\image-20201011170946927.png" alt="image-20201011170946927" style="zoom:50%;" />

***

**HTTP Response Message**

- This response message could be the response to the example request message just discussed

```
HTTP/1.1 200 OK
Connection: close
Date: Tue, 09 Aug 2011 15:44:04 GMT
Server: Apache/2.2.3 (CentOS)
Last-Modified: Tue, 09 Aug 2011 15:11:03 GMT
Content-Length: 6821
Content-Type: text/html

(data data data data data ...)
```

- It has three sections: an **initial status line**, six **header lines**, and then the **entity body**.
  - The entity body is the meat of the message—it contains the requested object itself (represented by data
    data data data data ...)
  - The status line has three fields: the **protocol version field**, a status code, and a **corresponding status message**.
  - Now let’s look at the header lines. 
    - The server uses the **Connection**: close header line to tell the client that it is going to close the TCP connection after sending the message. 
    - The **Date**: header line indicates the time and date when the HTTP response was created and sent by the server. 
    - The **Server**: header line indicates that the message was generated by an Apache Web server
    - The **Last-Modified**: header line indicates the time and date when the object was created or last modified. 
    - The **Content-Length**: header line indicates the number of bytes in the object being sent. 
    - The **Content**-**Type**: header line indicates that the object in the entity body is HTML text.

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\image-20201011185030673.png" alt="image-20201011185030673" style="zoom:50%;" />

Some common status codes and associated phrases include:

- **200** OK: Request succeeded and the information is returned in the response.
- **301** Moved Permanently: Requested object has been permanently moved;
  - the new URL is specified in Location: header of the response message. 
  - The client software will automatically retrieve the new URL.

- **400** Bad Request: This is a generic error code indicating that the request could not be understood by the server.
- **404** Not Found: The requested document does not exist on this server.
- **505** HTTP Version Not Supported: The requested HTTP protocol version is not supported by the server.

***

**User-Server Interaction: Cookies**

- it is often desirable for a Web site to identify users. For these purposes, HTTP uses cookies
- Cookies, defined in [**RFC 6265**], allow sites to keep track of users. 

- cookie technology has four components: 

  (1) a cookie header line in the HTTP response message;

  (2) a cookie header line in the HTTP request message; 

  (3) a cookie file kept on the user’s end system and managed by the user’s browser;

  (4) a back-end database at the Web site.

![img](C:\Users\13793\Desktop\学习笔记\计算机网络\Z}HQQVDI2PRF4APH{QS4YQ.png)

- The Amazon Web server then responds to Susan’s browser, including in the HTTP response a Set-cookie: header, which contains the identification number.

```
Set-cookie: 1678
```

***

**Web Caching**

- A Web cache—also called a **proxy server**—is a network entity that satisfies HTTP requests on the behalf of an origin Web server.
- The Web cache has its own disk storage and keeps copies of recently requested objects in this storage
- a user’s browser can be configured so that all of the user’s HTTP requests are first directed to the Web cache.
- As an example, suppose a browser is requesting the object http://www.someschool.edu/campus.gif. Here is what happens:
  - The browser establishes a TCP connection to the Web cache and sends an HTTP request for the object to the Web cache.
  - The Web cache checks to see if it has a copy of the object stored locally. If it does, the Web cache returns the object within an HTTP response message to the client browser.
  - If the Web cache does not have the object, the Web cache opens a TCP connection to the origin server, The Web cache then sends an HTTP request for the object into the cache-to-server TCP connection. After receiving this request, the origin server sends the object within an HTTP response to the Web cache.
  - When the Web cache receives the object, it stores a copy in its local storage and sends a copy, within an HTTP response message, to the client browser  (over the existing TCP connection between the client browser and the Web cache).

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\image-20201011191216185.png" alt="image-20201011191216185" style="zoom:50%;" />

Web caching has seen deployment in the Internet for two reasons. 

- First, a Web cache can substantially reduce the response time for a client request.
-  Second, Web caches can substantially reduce traffic on an institution’s access link to the Internet. 

***

**The Conditional GET**

- cache introduces a new problem—the copy of an object residing in the cache may be stale.

- HTTP has a mechanism that allows a cache to verify that itsobjects are **up to date**. This mechanism is called the **conditional GET.**

- The HTTP request is conditional GET message if 

  (1) the request message uses the GET method 

  (2) the request message includes an If-Modified-Since: header line.

- First, on the behalf of a requesting browser, a proxy cache sends a request message to a Web server:

  ```
  GET /fruit/kiwi.gif HTTP/1.1
  Host: www.exotiquecuisine.com
  ```

- Second, the Web server sends a response message with the requested object to the cache:

  ```
  HTTP/1.1 200 OK
  Date: Sat, 8 Oct 2011 15:39:29
  Server: Apache/1.3.0 (Unix)
  Last-Modified: Wed, 7 Sep 2011 09:23:24
  Content-Type: image/gif
  (data data data data data ...)
  ```

  The cache forwards the object to the requesting browser but also caches the object locally. Importantly, the cache also stores the **last-modified date** along with the object.

- Third, one week later, another browser **requests the same object via the cache**, and the object is still in the cache. Since this object may have been modified at the Web server in the past week, the cache performs **an up-to-date check** by issuing a conditional GET. 

  ```
  GET /fruit/kiwi.gif HTTP/1.1
  Host: www.exotiquecuisine.com
  If-modified-since: Wed, 7 Sep 2011 09:23:24
  ```

  the If-modified-since: header line is exactly equal to the value of the Last-Modified: header line that was sent by the server one week ago.

- Suppose the object **has not been modified** since 7 Sep 2011 09:23:24. Then, fourth, the Web server sends a response message to the cache:

  ```
  HTTP/1.1 304 Not Modified
  Date: Sat, 15 Oct 2011 15:39:29
  Server: Apache/1.3.0 (Unix)
  (empty entity body)
  ```

  We see that in response to the conditional GET, the Web server still sends a response message but does not include the requested object in the response message. 

  this last response message has **304 Not Modified** in the status line, which tells the cache that it can go ahead and forward its (the proxy cache’s) cached copy of the object to the requesting browser

***

### 2.3File Transfer: FTP

- The most striking difference is that FTP uses **two parallel TCP connections** to transfer a file,
- **a control connection and a data connection.** 
  - The ***control connection*** is used for sending control information between the two hosts—information such as user identification, password, commands to change remote directory, and commands to “put” and “get” files. 
  - The ***data connection*** is used to actually send a file.

***

### 2.4Electronic Mail in the Internet

**SMTP**

- To illustrate the basic operation of SMTP，Suppose Alice wants to send Bob a simple ASCII message.

  - Alice invokes her user agent for e-mail, provides Bob’s e-mail address  (for example,  bob@someschool.edu), composes a message, and instructs the user agent to send the message.

  - Alice’s user agent sends the message to her mail server, where it is placed in a **message queue**.

  - The client side of SMTP, running on Alice’s mail server, sees the message in the message queue. It **opens a TCP connection to an SMTP server**, running on Bob’s mail server.

  - After some initial SMTP handshaking, the SMTP client sends Alice’s message into the TCP connection

  - At Bob’s mail server, the server side of SMTP receives the message. Bob’s mail server then places the message in Bob’s mailbox.

  - Bob invokes his user agent to read the message at his convenience.

![image-20201011221647781](C:\Users\13793\Desktop\学习笔记\计算机网络\image-20201011221647781.png)

***

**Mail Message Formats**

```
From: alice@crepes.fr
To: bob@hamburger.edu
Subject: Searching for the meaning of life.
```

***

### 2.5DNS—The Internet’s Directory Service

**Services Provided by DNS**

- two ways to identify a host—by a hostname and by an IP address. 

- **domain name system (DNS)**

  (1)a distributed database implemented in a hierarchy of DNS servers
  (2)an application-layer protocol that allows hosts to query the distributed database.

- The DNS protocol runs over UDP and uses port 53.

- DNS is commonly employed by other application-layer protocols—including HTTP, SMTP, and FTP—to t**ranslate user-supplied hostnames to IP addresses.**

- This is done as follows.
  1. The same user machine runs the client side of the DNS application.

  2. The browser extracts the hostname, www.someschool.edu, from the URL 

    and passes the hostname to the client side of the DNS application.

  3. The DNS client sends a query containing the hostname to a DNS server.

  4. The DNS client eventually receives a reply, which includes the IP address for
      the hostname.

  5. Once the browser receives the IP address from DNS, it can initiate a TCP connection to the HTTP server process located at port 80 at that IP address.
  
- **DNS provides a few other important services**

  - **Host aliasing.** A host with a complicated hostname can have one or more alias names.

    For example, a hostname such as **relay1.west-coast.enter- prise.com** could have, say, two aliases such as **enterprise.com** and **www.enterprise.com**. the hostname **relay1.west-coast.enterprise.com** is said to be a **canonical hostname**（规范主机名）

  - **Mail server aliasing**. For obvious reasons, it is highly desirable that e-mail addresses be mnemonic. 

  - **Load distribution.（负载分配）** DNS is also used to perform load distribution among replicated servers, such as replicated Web servers. Busy sites are replicated over multiple servers, with each server running on a different end system and each having a different IP address. For replicated Web servers, **a set of IP addresses is thus associated with one canonical hostname**.

***

**Overview of How DNS Works**

- The application will invoke the client side of DNS, specifying the hostname that needs to be translated.
- DNS in the user’s host then takes over, sending a query message into the network.
- All DNS query and reply messages are sent within **UDP datagrams to port 53**. 
- After a delay, ranging from milliseconds to seconds, DNS in the user’s host receives a DNS reply message that provides the desired mapping.
- This mapping is then passed to the invoking application. 

***

**A Distributed, Hierarchical Database**

- To a first approximation, there are three classes of DNS servers—**root(根) DNS servers**, **top-level(顶级域) domain (TLD) DNS servers**, and **authoritative(权威) DNS servers**—organized in a hierarchy.

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\image-20201012203844063.png" alt="image-20201012203844063" style="zoom:50%;" />

- Step when send an HTTP request for host name
  - The client first contacts one of the root servers, which returns **IP addresses for TLD servers** for the top-level domain **com**. 
  - The client then contacts one of these TLD servers, which returns the IP address of **an authoritative server** for **amazon.com**.
  - Finally, the client contacts one of the authoritative servers for amazon.com, which returns the IP address for **the hostname www.amazon.com**.
- **Root DNS servers**. In the Internet there are 13 root DNS servers
- **Top-level domain (TLD) servers.** These servers are responsible for top-level domains such as com, org, net, edu, and gov, and all of the country top-level domains such as uk, fr, ca, and jp. 
- **Authoritative DNS servers.** Every organization with publicly accessible hosts (such as Web servers and mail servers) on the Internet must provide **publicly accessible DNS records** that map the names of those hosts to IP addresses. An organization’s authoritative DNS server houses these DNS records.

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\UI22ZW[[VL7Z82FC$9HYCS.png" alt="img" style="zoom:50%;" />

***

**DNS Caching**

- In a query chain, when a DNS server receives a DNS reply (containing, for example, a mapping from a hostname to an IP address), it can **cache the mapping in its local memory**. 
- another query arrives to the DNS server for the same hostname, the DNS server can provide the desired IP address
- DNS servers discard cached information after a period of time (often set to two days).

***

**DNS Records and Messages**

The DNS servers that together implement the DNS distributed database store **resource records (RRs)**, including RRs that provide hostname-to-IP address mappings.

A resource record is a four-tuple that contains the following fields:

```
(Name, Value, Type, TTL)
```

- TTL is the time to **live of the resource record**; it determines when a resource should be removed from a cache.
- The meaning of **Name** and **Value** depend on **Type**:
  - If **Type = A**, then Name is a hostname and Value is the IP address for the hostname. 
  - If **Type = NS**, then Name is a domain (such as foo.com) and Value is the hostname of an authoritative DNS server that knows how to obtain the IP addresses for hosts in the domain.
  - If **Type = MX**, then Value is the canonical name of a mail server that has an alias hostname Name.

***

**DNS Messages**

The semantics of the various fields in aDNS message are as follows:

- The first 12 bytes is the header section, which has a number of fields.

  - The first fieldis a 16-bit number that identifies the query.This identifier is copied into the reply message to a query, allowing the client to **match received replies with sent queries**.

  - There are a number of flags in the flag field. 

    - A 1-bit query/reply flag **indicates whether the message is a query (0) or a reply (1)**. 
    - A 1-bit authoritative flag is set in a reply message when a DNS server is **an authoritative server for a queried name**
    - A 1-bit recursion-desired flag is set when a client (host or DNS server) desires that the DNS server **perform recursion** when it doesn’t have the record.
    - A 1-bit recursion-available field is set in a reply if the DNS server **supports recursion**.

  - **The question section** contains information about the query that is being made.This section includes 

    (1) a name field that contains the name that is being queried

    (2) a type field that indicates the type of question being asked about the name—for example, a host address associated with a name (Type A) or the mail server for a name (Type MX)

  - **The answer section** contains the resource records for the name that was originally queried. 

  - **The authority section** contains records of other authoritative servers.

  - **The additional section** contains other helpful records.

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\image-20201012222139709.png" alt="image-20201012222139709" style="zoom:50%;" />

> from a Windows host, open the Command Prompt and invoke the nslookup program by simply typing **“nslookup.”** After invoking nslookup, you can send a DNS query to any DNS server (root, TLD, or authoritative). After receiving the reply message from the DNS server, nslookup will display the records included in the reply (in a human-readable format).

***

**Inserting Records into the DNS Database**

- The first thing you’ll surely want to do is **register the domain name networkutopia.com at a registrar**. 
- A registrar is a commercial entity that verifies the uniqueness of the domain name, enters the domain name into the DNS database (as discussed below), and collects a small fee from you for its services. 

***

### 2.6Peer-to-Peer Applications

**Distributed Hash Tables (DHTs)**

Let’s begin by describing a centralized version of this simple database, which will simply contain (key, value) **pairs**. 

- For example, the keys could be social security numbers and the values could be the corresponding human names, in this case, an example key-value pair is (156-45-7081, Johnny Wu).
- We query the database **with a key**.
- If there are one or more key-value pairs in the database that match the query key, the database **returns the corresponding values**. 
  - for example, if the database stores social security numbers and their corresponding human names, we can query with a specific social security number, and the database returns the name of the human who has that social security number. 

>We’ll allow any peer to query the distributed database **with a particular key**. The distributed database will then **locate the peers** that have the corresponding (key, value) pairs and **return the key-value pairs** to the querying peer. Any peer will also be allowed to insert new key-value pairs into the database. Such a distributed database is referred to as a **distributed hash table (DHT)**.

***

**We now describe an elegant approach to designing a DHT.** 

- let’s first assign an identifier to each peer, where each identifier is an integer in the range[0, 2^n^-1] for some fixed n.

- Note that each such identifier can be expressed by an n-bit representation. Let’s also require **each key to be an integer in the same range**. 

> A hash function is a many-to-one function for which two different inputs can have the same output.
>
> but the likelihood of the having the same output is extremely small.

**Circular DHT**

- Using the circular overlay, the origin peer (peer 3) creates a message saying and sends this message clockwise around the circle. 
- If a peer is not responsible for the key, it simply sends the message to its successor. 

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\D9LSF$]X[9KSZZTPIPAX}7U.png" alt="img" style="zoom:50%;" />

>The circular DHT provides a very elegant solution for reducing the amount of overlay information each peer must manage.
>
>In designing a DHT, there is tradeoff between the number of neighbors each peer has to track and the number of messages that the DHT needs to send to resolve a single query.

***

### 2.7Socket Programming: Creating Network Applications

**Socket Programming with UDP**

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\4.png" style="zoom:50%;" />

**UDPClient.py**
Here is the code for the client side of the application:

```python
from socket import *
serverName = ‘hostname’
serverPort = 12000
clientSocket = socket(socket.AF_INET, socket.SOCK_DGRAM)
message = raw_input(’Input lowercase sentence:’)
clientSocket.sendto(message,(serverName, serverPort))
modifiedMessage, serverAddress = clientSocket.recvfrom(2048)
print modifiedMessage
clientSocket.close()
```

- The **socket** module forms the basis of all network communications in Python. By including this line, we will be able to create sockets within our program.

```
serverName = ‘hostname’
serverPort = 12000
```

- The first line sets the string serverName to hostname. Here, we provide a string containing either the IP address of the server (e.g., “128.138.32.126”) or the hostname of the server (e.g., “cis.poly.edu”).

***

```
clientSocket = socket(socket.AF_INET, socket.SOCK_DGRAM)
```

- This line creates the client’s socket, called clientSocket.
- The first parameter indicates the address family; in particular, **AF_INET** indicates that the underlying
  network is using **IPv4**. 
- The second parameter indicates that the socket is of type **SOCK_DGRAM**, which means it is a UDP socket (rather than a TCP socket). 
- Note that we are not specifying the **port number of the client socket** when we create it; we are instead letting **the operating system do this** for us. 

***

```
message = raw_input(’Input lowercase sentence:’)
```

- Now that the client process’s door has been created, we will want to create a message to send through the door.

```
clientSocket.sendto(message,(serverName, serverPort))
```

- the method sendto() attaches the destination address (serverName, serverPort) to the message and sends the resulting packet into the process’s socket, clientSocket. 
- After sending the packet, the client waits to receive data from the server.

***

```
modifiedMessage, serverAddress = clientSocket.recvfrom(2048)
```

- With the above line, when a packet arrives from the Internet at the client’s socket, the packet’s data is put into the variable modifiedMessage 
- and the packet’s source address is put into the variable serverAddress.

***

```
clientSocket.close()
```


This line closes the socket. The process then terminates.

***

**UDPServer.py**
Let’s now take a look at the server side of the application:

```python
from socket import *
serverPort = 12000
serverSocket = socket(AF_INET, SOCK_DGRAM)
serverSocket.bind((’’, serverPort))
print ”The server is ready to receive”
while 1:
    message, clientAddress = serverSocket.recvfrom(2048)
    modifiedMessage = message.upper()
    serverSocket.sendto(modifiedMessage, clientAddress)
```

The above line binds (that is, assigns) the port number 12000 to the server’s socket.

```
serverSocket.bind((’’, serverPort))
```

Thus in UDPServer, the code (written by the application developer) is explicitly assigning a port number to the socket. 

***

**Socket Programming with TCP**

**TCPClient.py**
Here is the code for the client side of the application:

```
from socket import *
serverName = ’servername’
serverPort = 12000
clientSocket = socket(AF_INET, SOCK_STREAM)
clientSocket.connect((serverName,serverPort))
sentence = raw_input(‘Input lowercase sentence:’)
clientSocket.send(sentence)
modifiedSentence = clientSocket.recv(1024)
print ‘From Server:’, modifiedSentence
clientSocket.close()
```

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\S37DQMF}6B`M$ZJ6G9S$ZYI.png" alt="img" style="zoom:50%;" />

**TCPServer.py**
Now let’s take a look at the server program.

```python
from socket import *
serverPort = 12000
serverSocket = socket(AF_INET,SOCK_STREAM)
serverSocket.bind(('',serverPort))
serverSocket.listen(1)
print ('The server is ready to receive')
while 1:
    connectionSocket, addr = serverSocket.accept()
    sentence = connectionSocket.recv(1024)
    capitalizedSentence = sentence.upper()
    connectionSocket.send(capitalizedSentence)
    connectionSocket.close()
```

***

## 3.Transport Layer

### 3.1 Introduction and Transport-Layer Services

> A transport-layer protocol provides for logical communication between application processes running on different hosts. 

***

### 3.2 Multiplexing and Demultiplexing

>In this section, we discuss transport-layer multiplexing and demultiplexing, that is:
>
>Extending the host-to-host delivery service provided by the network layer to a process-to-process delivery service for applications running on the hosts. 

- At the destination host, the transport layer receives segments from the network layer just below. 
  
- The transport layer has the responsibility of delivering the data in these segments to the appropriate application process running in the host. **(**a process (as part of a network application) can have one or more sockets**)**
  
- Now let’s consider how a receiving host directs an incoming transport-layer segment to the appropriate socket. 

  >Each transport-layer segment has ***a set of fields*** in the segment for this purpose. 
  >
  >At the receiving end, the transport layer examines these fields to identify the receiving socket and then directs the segment to that socket. 
  >
  >This job of delivering the data in a transport-layer segment to the correct socket is called **demultiplexing**. 
  >
  >***
  >
  >The job of gathering data chunks at the source host from different sockets, encapsulating each data chunk with header information (that will later be used in demultiplexing) to create segments, and passing the segments to the network layer is called **multiplexing**. 

- Now that we understand the roles of transport-layer multiplexing and demultiplexing, let us examine how it is actually done in a host. 

  > Transport-layer multiplexing requires 
  >
  > (1) that sockets have unique identifiers
  >
  > (2) that each segment have special fields that indicate the socket to which the segment is to be delivered. 
  >
  > These special fields, are the ***source port number field*** and ***the destination port number field***. 
  >
  > Each port number is a 16-bit number, ranging from 0 to 65535. 
  >
  > The port numbers ranging from 0 to 1023 are called well-known port numbers and are restricted, which means that they are reserved for use by well-known application protocols such as HTTP. 

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\image-20201116191935976.png" alt="image-20201116191935976" style="zoom:50%;" />

***

**Connectionless Multiplexing and Demultiplexing**

>It is important to note that a UDP socket is fully identified by a two-tuple consisting of a destination IP address and a destination port number. 

**Connection-Oriented Multiplexing and Demultiplexing**

>In order to understand TCP demultiplexing, we have to take a close look at TCP sockets and TCP connection establishment.
>
>One subtle difference between a TCP socket and a UDP socket is that a TCP socket is identified by a four-tuple: (source IP address, source port number, destination IP address, destination port number).

- In particular, and in contrast with UDP, two arriving TCP segments with different source IP addresses or source port numbers will (with the exception of a TCP segment carrying the original connection-establishment request) be directed to two different sockets. 

- To gain further insight, let’s reconsider the TCP client-server programming example in Section 2.7.2:
  - The TCP server application has a “welcoming socket,” that waits for connection-establishment requests from TCP clients on port number 12000.
  - The TCP client creates a socket and sends a connection establishment request segment .
  - A connection-establishment request is nothing more than a TCP segment with destination port number 12000 and a special connection-establishment bit set in the TCP header. The segment also includes a source port number that was chosen by the client.
  - When the host operating system of the computer running the server process receives segment with destination port 12000, it locates the server process that is waiting to accept a connection on port number 12000. The server process then creates a new socket.
  - Also, the transport layer at the server notes the following four values in the connection-request segment.
  - The newly created connection socket is identified by these four values; all subsequently arriving segments  match these four values will be demultiplexed to this socket. 

***

**Web Servers and TCP**

> Consider a host running a Web server, such as an Apache Web server, on port 80. 
>
> When clients send segments to the server, all segments will have destination port 80. 
>
> The server distinguishes the segments from the different clients using source IP addresses and source port numbers.

- A Web server spawns a new process for each connection. 
  - Each of these processes has its own connection socket through which HTTP requests arrive and HTTP responses are sent. 
  - We mention, however, that there is not always a one-to-one correspondence between connection
    sockets and processes. Web servers often use only one process, and ***create a new thread*** with a new connection socket for each new client connection. (A thread can be viewed as a lightweight subprocess.) 

***

### 3.3 Connectionless Transport: UDP

> Many applications are better suited for UDP for the following reasons:

- Finer application-level control over what data is sent, and when. 
- No connection establishment. 
- No connection state. 
- Small packet header overhead.

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\5.png" style="zoom:50%;" />

***

**UDP Segment Structure**

>The application data occupies the data field of the UDP segment. 
>
>For example, for DNS, the data field contains either a query message or a response message. 
>
>For a streaming audio application, audio samples fill the data field. 

- The UDP header has only four fields, each consisting of two bytes.
  - The length field specifies the number of bytes in the UDP segment (header plus data). An explicit length value is needed since the size of the data field may differ from one UDP segment to the next. 
  - The checksum is used by the receiving host to check whether errors have been introduced into the segment. 

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\image-20201116220710942.png" alt="image-20201116220710942" style="zoom:50%;" />

***

**UDP Checksum**

>The UDP checksum provides for error detection. That is, the checksum is used to determine whether bits within the UDP segment have been altered (for example, by noise in the links or while stored in a router) as it moved from source to destination.

- As an example, suppose that we have the following three 16-bit words:

0110011001100000
0101010101010101
1000111100001100

- Note that this last addition had overflow, which was wrapped around. The 1s complement is obtained by converting all the 0s to 1s and converting all the 1s to 0s.
- At the receiver, all four 16-bit words are added, including the checksum. 
  - If no errors are introduced into the packet, then clearly the sum at the receiver will be 1111111111111111. 
  - If one of the bits is a 0, then we know that errors have been introduced into the packet.

***

### 3.4 Principles of Reliable Data Transfer

>The service abstraction provided to the upper-layer entities is that of a reliable channel through which data can be transferred. 
>
>With a reliable channel, no transferred data bits are corrupted (flipped from 0 to 1, or vice versa) or lost, and all are delivered in the order in which they were sent. 
>
>It is the responsibility of a **reliable data transfer protocol** to implement this service abstraction. 
>
>This task is made difficult by the fact that the layer below the reliable data transfer protocol may be unreliable. 
>
>For example, TCP is a reliable data transfer protocol that is implemented on top of an unreliable (IP) end-to-end net-work layer. 

- One assumption we’ll adopt throughout our discussion here is that packets will be delivered in the order in which they were sent, with some packets possibly being lost; that is, the underlying channel will not reorder packets. 

![](C:\Users\13793\Desktop\学习笔记\计算机网络\6.png)

- The sending side of the data transfer protocol will be invoked from above by a call to **rdt_send()**. 
  - It will pass the data to be delivered to the upper layer at the receiving side. (Here rdt stands for ***reliable data transfer*** protocol)
- On the receiving side, **rdt_rcv()** will be called when a packet arrives from the receiving side of the channel. 
- When the rdt protocol wants to deliver data to the upper layer, it will do so by calling **deliver_data()**
- Both the send and receive sides of rdt send packets to the other side by a call to **udt_send()** (where udt stands for ***unreliable data transfer***).

> In this section we consider only the case of ***unidirectional data transfer***, that is, data transfer from the sending to the receiving side. 

***

**Building a Reliable Data Transfer Protocol**

>We now step through a series of protocols, each one becoming more complex, arriving at a flawless, reliable data transfer protocol.

***

*Reliable Data Transfer over a Perfectly Reliable Channel: rdt1.0*

>We first consider the simplest case, in which the underlying channel is completely reliable. 
>
>The **finite-state machine (FSM)** definitions for the rdt1.0 sender and receiver are shown below. 
>
>The FSM in Figure 3.9(a) defines the operation of the sender, while the FSM in Figure 3.9(b) defines the operation of the receiver. 
>
>It is important to note that there are separate FSMs for the sender and for the receiver. 
>
>The event causing the transition is shown above the horizontal line labeling the transition, and the actions taken when the event occurs are shown below the horizontal line. 
>
>The initial state of the FSM is indicated by the dashed arrow.

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\image-20201117184006874.png" alt="image-20201117184006874" style="zoom:50%;" />

>The sending side of rdt simply accepts data from the upper layer via the **rdt_send(data)** event, creates a packet containing the data (via the action **make_pkt(data)**) and sends the packet into the channel. 
>
>On the receiving side, rdt receives a packet from the underlying channel via the **rdt_rcv(packet)** event, removes the data from the packet (via the action **extract (packet, data)**) and passes the data up to the upper layer (via the action **deliver_data(data)**). 

***

*Reliable Data Transfer over a Channel with Bit Errors: rdt2.0*

>A more realistic model of the underlying channel is one in which bits in a packet may be corrupted. 
>
>Such bit errors typically occur in the physical components of a network as a packet is transmitted, propagates, or is buffered. 
>
>We’ll continue to assume for the moment that all transmitted packets are received (although their bits may be corrupted) in the order in which they were sent.

- Consider how you yourself might dictate a long message over the phone. 
  - This message-dictation protocol uses both **positive acknowledgments** (“OK”) and **negative acknowledgments** (“Please repeat that.”). 
  - These control messages allow the receiver to let the sender know what has been received correctly, and what has been received in error and thus requires repeating. 
  - In a computer network setting, reliable data transfer protocols based on such retransmission are known as **ARQ (Automatic Repeat reQuest)** protocols.
- Fundamentally, three additional protocol capabilities are required in ARQ protocols to handle the presence of bit errors:
  - *Error detection.* First, a mechanism is needed to allow the receiver to detect when bit errors have occurred. 
  - *Receiver feedback*. Since the sender and receiver are typically executing on different end systems, the only way for the sender to learn of the receiver’s view of the world is for the receiver to provide explicit feedback to the sender. 
  - *Retransmission.* A packet that is received in error at the receiver will be retransmitted by the sender.

![img](C:\Users\13793\Desktop\学习笔记\计算机网络\F[SC_Y@GE`Q4VH@@V6[9CBO.png)

The send side of rdt2.0 has two states. 

- In the leftmost state, the send-side protocol is waiting for data to be passed down from the upper layer. 

  - When the **rdt_send(data)** event occurs, the sender will create a packet (sndpkt) containing the data to be sent, along with a packet checksum , and then send the packet via the **udt_send(sndpkt)** operation. 

- In the rightmost state, the sender protocol is waiting for an ACK or a NAK packet from the receiver. 

  - If an ACK packet is received (the notation rdt_rcv(rcvpkt) && isACK (rcvpkt) corresponds to this event), the sender knows that the most recently transmitted packet has been received correctly and thus the protocol ***returns to the state*** of waiting for data from the upper layer. 

  - If a NAK is received, the protocol ***retransmits*** the last packet and waits for an ACK or NAK to be returned by the receiver in response to the retransmitted data packet. 

  > It is important to note that *when the sender is in the wait-for-ACK-or-NAK state*, it cannot get more data from the upper layer; that is, the rdt_send() event can not occur; that will happen only after the sender receives an ACK and leaves this state. 
  >
  > Because of this behavior, protocols such as rdt2.0 are known as ***stop-and-wait protocols***.

The receiver-side FSM for rdt2.0 still has a single state. 

- On packet arrival, the receiver replies with either an ACK or a NAK, depending on whether or not the
  received packet is corrupted. 

> Protocol rdt2.0 may look as if it works but, unfortunately, it has a fatal flaw. In particular, we haven’t accounted for ***the possibility that the ACK or NAK packet could be corrupted***! 

- A simple solution to this new problem is to *add a new field to the data packet* and have the sender number its data packets by putting **a sequence number** into this field. 

***

Figures 3.11 and 3.12 show the FSM description for rdt2.1, our fixed version of rdt2.0. 

> The rdt2.1 sender and receiver FSMs each now have twice as many states as before. This is because the protocol state must now reflect *whether the packet currently being sent (by the sender) or expected (at the receiver)* should have a sequence number of 0 or 1. 

![](C:\Users\13793\Desktop\学习笔记\计算机网络\7.png)

![](C:\Users\13793\Desktop\学习笔记\计算机网络\01.png)

***

*Reliable Data Transfer over a Lossy Channel with Bit Errors: rdt3.0*

>Suppose now that in addition to corrupting bits, the underlying channel can ***lose packets*** as well, a not-uncommon event in today’s computer networks (including the Internet). 
>
>Two additional concerns must now be addressed by the protocol: 
>
>how to detect packet loss and what to do when packet loss occurs. 
>
>Here, we’ll put the burden of detecting and recovering from lost packets on the sender. 
>
>Suppose that the sender transmits a data packet and either that packet, or the receiver’s ACK of that packet, gets lost. In either case, no reply is forthcoming at the sender from the receiver. 



![](C:\Users\13793\Desktop\学习笔记\计算机网络\9.png)

***

**Pipelined Reliable Data Transfer Protocols**

> At the heart of rdt3.0’s performance problem is the fact that it is a ***stop-and-wait protocol***.

![image-20201118105915278](C:\Users\13793\Desktop\学习笔记\计算机网络\image-20201118105915278.png)

>The solution to this particular performance problem is simple: Rather than operate in a stop-and-wait manner, the sender is allowed to send multiple packets without waiting for acknowledgments

- Pipelining has the following consequences for reliable data transfer protocols:
  - The ***range of sequence numbers must be increased***, since each in-transit packet (not counting retransmissions) must have a unique sequence number and there may be multiple, in-transit, unacknowledged packets.
  - The sender and receiver sides of the protocols may have to ***buffer more than one packet***. Minimally, the sender will have to buffer packets that have been transmitted but not yet acknowledged. 
  - The range of sequence numbers needed and the buffering requirements will depend on the manner in which a data transfer protocol responds to lost, corrupted, and overly delayed packets. 
- Two basic approaches toward pipelined error recovery can be identified: **Go-Back-N** and **selective repeat**.

***

**Go-Back-N (GBN)**

>In a Go-Back-N (GBN) protocol, the sender is allowed to transmit multiple packets (when available) without waiting for an acknowledgment, but is constrained to have ***no more than some maximum allowable number, N***, of unacknowledged packets in the pipeline. 

![image-20201118111459534](C:\Users\13793\Desktop\学习笔记\计算机网络\image-20201118111459534.png)

- Figure 3.19 shows the sender’s view of the range of sequence numbers in a GBN protocol. 
  - If we define **base** to be the sequence number of the oldest unacknowledged packet and **nextseqnum** to be the smallest unused sequence number (that is, the sequence number of the next packet to be sent), then four intervals in the range of sequence numbers can be identified. 
    - Sequence numbers in the interval **[0,base-1]** correspond to packets that have already been transmitted and acknowledged. 
    - Sequence numbers in the interval **[nextseqnum,base+N-1]** can be used for packets that can be sent immediately, should data arrive from the upper layer. 
    - Finally, sequence numbers greater than or equal to base+N cannot be used until an unacknowledged packet currently in the pipeline (specifically, the packet with sequence number base) has been acknowledged.

- In practice, a packet’s sequence number is carried in a fixed-length field in the packet header. If k is the number of bits in the packet sequence number field, the range of sequence numbers is thus [0,2^k^– 1]. 
  - We will see in Section 3.5 that TCP has a 32-bit sequence number field, where TCP sequence numbers count bytes in the byte stream rather than packets.

![](.\11.png)

<img src=".\110.png" style="zoom:50%;" />

- The GBN sender must respond to three types of events:

  - ***Invocation from above***. When rdt_send() is called from above, the sender first checks to see if the window is full. 

    - If the window is not full, a packet is created and sent, and variables are appropriately updated. 
    - If the window is full, the sender simply returns the data back to the upper layer, an implicit indication that the window is full. 

    >In a real implementation, the sender would more likely have either buffered (but not immediately sent) this data, or would have a synchronization mechanism (for example, a semaphore or a flag) that would allow the upper layer to call rdt_send() only when the window is not full.

  - ***Receipt of an ACK.*** In our GBN protocol, an acknowledgment for a packet with sequence number n will be taken to be a cumulative acknowledgment, indicating that all packets with a sequence number up to and including n have been correctly received at the receiver. 
  - ***A timeout event.*** If a timeout occurs, the sender resends all packets that have been previously sent but that have not yet been acknowledged. 
    
    - If an ACK is received but there are still additional transmitted but not yet acknowledged packets, the timer is restarted. If there are no outstanding, unacknowledged packets, the timer is stopped.

***

**Selective Repeat (SR)**

>In particular, when the window size and bandwidth-delay product are both large, many packets can be in the pipeline. A single packet error can thus cause GBN to retransmit a large number of packets, many unnecessarily. As the probability of channel errors increases, the pipeline can become filled with these unnecessary retransmissions. 

>As the name suggests, selective-repeat protocols avoid unnecessary retransmissions by having the sender retransmit ***only those packets that it suspects were received in error*** (that is, were lost or corrupted) at the receiver. 

![](.\111.png)

- However, unlike GBN, the sender will have already received ACKs for some of the packets in the window. 

<img src=".\1110.png" style="zoom:50%;" />

- Figure 3.24 details the various actions taken by the SR sender.
- The SR receiver will acknowledge a correctly received packet whether or not it is in order. 
  - Out-of-order packets are buffered until any missing packets (that is, packets with lower sequence numbers) are received, at which point a batch of packets can be delivered in order to the upper layer. 

<img src=".\image-20201118151437158.png" alt="image-20201118151437158" style="zoom:50%;" />

- Figure 3.25 itemizes the various actions taken by the SR receiver. 

****

### 3.5 Connection-Oriented Transport: TCP

**The TCP Connection**

>TCP is said to be connection-oriented because before one application process can begin to send data to another, the two processes must first “***handshake***” with each other—that is, they must ***send some preliminary segments*** to each other to ***establish the parameters*** of the ensuing data transfer. 
>
>As part of TCP connection establishment, both sides of the connection will initialize many TCP state variables associated with the TCP connection.

- A TCP connection provides a **full-duplex service**.

- A TCP connection is also always **point-to-point**, that is, between a single sender and a single receiver. 

  ***

- Let’s now take a look at how a TCP connection is established. 

  - Suppose a process running in one host wants to initiate a connection with another process in another host. 
    - Recall that the process that is initiating the connection is called the *client process*, while the other process is called the *server process*. 
  - The client application process first ***informs the client transport layer*** that it wants to establish a connection to a process in the server.
    - The client first sends a special TCP segment; 
    - the server responds with a second special TCP segment; 
    - and finally the client responds again with a third special segment. 
    - The first two segments carry no payload, that is, no application-layer data; the third of these segments may carry a payload. 
  - Because three segments are sent between the two hosts, this connection-establishment procedure is often referred to as a **three-way handshake**.

<img src=".\image-20201119153215241.png" alt="image-20201119153215241" style="zoom:50%;" />

- Once the data passes through the door, the data is in the hands of TCP running in the client. 
  - As shown in Figure 3.28, TCP directs this data to the connection’s **send buffer,** which is one of the buffers that is set aside during the initial three-way handshake.
- From time to time, TCP will grab chunks of data from the send buffer and pass the data to the network layer. 
- The maximum amount of data that can be grabbed and placed in a segment is limited by the **maximum segment size (MSS)**. 
  - The MSS is typically set by first determining the length of the largest link-layer frame that can be sent by the local sending host (the so-called **maximum transmission unit**, ***MTU***), and then setting the MSS to ensure that a TCP segment (when encapsulated in an IP datagram) plus the TCP/IP header length (typically 40 bytes) will fit into a single link-layer frame. 
  - Note that the MSS is the maximum amount of application-layer data in the segment, not the maximum size of the TCP segment including headers. 

- TCP pairs each chunk of client data with a TCP header, thereby forming **TCP segments**. 

***

#### **TCP Segment Structure**

>The TCP segment consists of header fields and a data field. 
>
>The data field contains a chunk of application data. 

<img src=".\image-20201119155835823.png" alt="image-20201119155835823" style="zoom:50%;" />

- As with UDP, the header includes source and destination port numbers, which are used for multiplexing/demultiplexing data from/to upper-layer applications. 
- Also, as with UDP, the header includes a checksum field. 
- A TCP segment header also contains the following fields:
  - The 32-bit **sequence number field** and the 32-bit **acknowledgment number field** are used by the TCP sender and receiver in implementing a reliable data transfer service, as discussed below.
  - The 16-bit **receive window field** is used for flow control. We will see shortly that it is used to indicate the number of bytes that a receiver is willing to accept.
  - The 4-bit **header length field** specifies the length of the TCP header in 32-bit words. The TCP header can be of variable length due to the TCP options field. 
    - Typically, the options field is empty, so that the length of the typical TCP header is 20 bytes.
  - The **flag field** contains 6 bits. 
    - The **ACK bit** is used to indicate that the value carried in the acknowledgment field is valid; that is, the segment contains an acknowledgment for a segment that has been successfully received. 
    - The **RST**, **SYN**, and **FIN** bits are used for ***connection setup and teardown***, as we will discuss at the end of this section. 
    - Setting the **PSH** bit indicates that the receiver should pass the data to the upper layer immediately. 
    - Finally, the **URG** bit is used to indicate that there is data in this segment that the sending-side upper-layer entity has marked as “urgent.” The location of the last byte of this urgent data is
      indicated by the 16-bit **urgent data pointer field**. TCP must inform the receiving-side upper-layer entity when urgent data exists and pass it a pointer to the end of the urgent data. (In practice, the PSH, URG, and the urgent data pointer are not used. However, we mention these fields for completeness.)

***

*Sequence Numbers and Acknowledgment Numbers*

> Two of the most important fields in the TCP segment header are the sequence number field and the acknowledgment number field. 

- let us first explain what exactly TCP puts in these fields.

  - TCP views data as an unstructured, but ordered, stream of bytes. 
  - TCP’s use of sequence numbers reflects this view in that sequence numbers are over ***the stream of***
    ***transmitted bytes*** and not over the series of transmitted segments. 

  >Suppose that a process in Host A wants to send a stream of data to a process in Host B over a TCP connection. 
  >
  >The TCP in Host A will implicitly number each byte in the data stream. Suppose that the data stream consists of 500,000 bytes, that the MSS is 1,000 bytes, and that the first byte of the data stream is numbered 0. 
  >
  >TCP constructs 500 segments out of the data stream. 
  >
  >The first segment gets assigned sequence number 0, the second segment gets assigned sequence number 1,000, the third segment gets assigned sequence number 2,000, and so on. 
  >
  >Each sequence number is inserted in the sequence number field in the header of the appropriate TCP segment.

  - The acknowledgment number that Host A puts in its segment is **the sequence number of the next byte** Host A is expecting from Host B. 

    > Suppose that Host A has received all bytes numbered 0 through 535 from B and suppose that it is about to send a segment to Host B. 
    >
    > Host A is waiting for byte 536 and all the subsequent bytes in Host B’s data stream. So Host A puts 536 in the acknowledgment number field of the segment it sends to B.
    >
    > ***
    >
    > Suppose that Host A has received one segment from Host B containing bytes 0 through 535 and another segment containing bytes 900 through 1,000. 
    >
    > For some reason Host A has not yet received bytes 536 through 899. 
    >
    > In this example, Host A is ***still waiting for byte 536*** (and beyond) in order to re-create B’s data stream. 

  - Because TCP only acknowledges bytes up to the first missing byte in the stream, TCP is said to provide **cumulative acknowledgments**.

<img src=".\image-20201119214947166.png" alt="image-20201119214947166" style="zoom:50%;" />

***

**Telnet: A Case Study for Sequence and Acknowledgment Numbers**

- Suppose Host A initiates a Telnet session with Host B. Because Host A initiates the session, it is labeled the client, and Host B is labeled the server.
- Each character typed by the user (at the client) will be sent to the remote host
- the remote host will send back a copy of each character, which will be displayed on the Telnet user’s
  screen. 
- This “echo back” is used to ***ensure*** that characters seen by the Telnet user have already been received and processed at the remote site. 
- Each character thus traverses the network twice between the time the user hits the key and the time the character is displayed on the user’s monitor.

<img src=".\1111.png" style="zoom: 40%;" />

***

**Round-Trip Time Estimation and Timeout**

***

#### Computing TCP's Retransmission Timer

> To compute the current RTO, a TCP sender maintains two state variables
>
> `SRTT (smoothed round-trip time)` and `RTTVAR (round-trip time variation)`. 

- The rules governing the computation of SRTT, RTTVAR, and RTO are as follows:
  - Until a round-trip time (RTT) measurement has been made for a segment sent between the sender and receiver, the sender SHOULD set `RTO <- 1 second`.
  - When the first RTT measurement R is made, the host MUST set
    `SRTT <- R
    RTTVAR <- R/2
    RTO <- SRTT + max (G, K*RTTVAR)
    where K = 4.	`
  - When a subsequent RTT measurement R' is made, a host MUST set
    `RTTVAR <- (1 - beta) * RTTVAR + beta * |SRTT - R'|
    SRTT <- (1 - alpha) * SRTT + alpha * R'` 
    - The above SHOULD be computed using alpha=1/8 and beta=1/4
    - After the computation, a host MUST update
      `RTO <- SRTT + max (G, K*RTTVAR)` 
  - Whenever RTO is computed, if it is less than 1 second, then the RTO SHOULD be rounded up to 1 second.
  - A maximum value MAY be placed on RTO provided it is at least 60 seconds.
- **Managing the RTO Timer**
  - Every time a packet containing data is sent (including a retransmission), if the timer is not running, start it running so that it will expire after RTO seconds.
  - When all outstanding data has been acknowledged, turn off the retransmission timer.
  - When an ACK is received that acknowledges new data, restart the retransmission timer so that it will expire after RTO seconds.
- **When the retransmission timer expires, do the following:**
  - Retransmit the earliest segment that has not been acknowledged by the TCP receiver.
  - The host MUST set RTO <- RTO * 2 ("back off the timer"). 
  - Start the retransmission timer, such that it expires after RTO seconds.
  - If the timer expires awaiting the ACK of a SYN segment and the TCP implementation is using an RTO less than 3 seconds, the RTO MUST be re-initialized to 3 seconds when data transmission begins.

>Choosing a reasonable initial RTO requires balancing two competing considerations:
>
>- The initial RTO should be sufficiently large to cover most of the end-to-end paths to avoid spurious retransmissions.
>- The initial RTO should be small enough to ensure a timely recovery from packet loss occurring before an RTT sample is taken.

***

**Estimating the Round-Trip Time [RFC 6298]**

>Let’s begin our study of TCP timer management by considering how TCP estimates the round-trip time between sender and receiver. This is accomplished as follows.

- The sample RTT, denoted SampleRTT, for a segment is the amount of time between *when the segment is sent* (that is, passed to IP) and *when an acknowledgment for the segment is received*. 

- Instead of measuring a SampleRTT for every transmitted segment, most TCP implementations take only ***one SampleRTT measurement*** at a time. 

  - That is, at any point in time, the SampleRTT is being estimated for only one of the **transmitted but currently unacknowledged** segments, leading to a new value of SampleRTT approximately once every RTT. 

  - Also, TCP never computes a SampleRTT for a segment that has been retransmitted; it only measures SampleRTT for segments that have been transmitted once.

    > The round trip time is estimated as the difference between the time that a segment was sent and the time that its acknowledgment was returned to the sender, but when packets are retransmitted there is an ambiguity: the acknowledgment may be a response to the first transmission of the segment or to a subsequent re-transmission. [Wikipedia]

***

**Setting and Managing the Retransmission Timeout Interval**

>An initial TimeoutInterval value of 1 second is recommended [RFC 6298].
>Also, when a timeout occurs, the value of TimeoutInterval is **doubled** to avoid a premature timeout occurring for a subsequent segment that will soon be acknowledged. 

***

**Reliable Data Transfer**

>TCP creates a **reliable data transfer service** on top of IP’s unreliable best-effort service. 
>
>Code below presents a highly simplified description of a TCP sender. 

```c
/* Assume sender is not constrained by TCP flow or congestion control, that data from above is less than MSS in size, and that data transfer is in one direction only. */
NextSeqNum = InitialSeqNumber
SendBase = InitialSeqNumber
loop (forever) {
    switch(event)
        
        event: data received from application above
            create TCP segment with sequence number NextSeqNum
            if (timer currently not running)
                start timer
                pass segment to IP
                NextSeqNum=NextSeqNum+length(data)
            break;
    
        event: timer timeout
            retransmit not-yet-acknowledged segment with
            smallest sequence number
            start timer
            break;
    
        event: ACK received, with ACK field value of y
            if (y > SendBase) {
                SendBase=y
                if (there are currently any not-yet-acknowledged segments)
            		start timer
            }
            break;
} /* end of loop forever */
```

- We see that there are three major events related to data transmission and retransmission in the TCP sender: 
  - data received from application above
  - timer timeout
  - ACK receipt. 
    - Upon the occurrence of the first major event, TCP receives data from the application, encapsulates the data in a segment, and passes the segment to IP. 
    - Also note that if the timer is already not running for some other segment, TCP starts the timer when the segment is passed to IP. 
    - The expiration interval for this timer is the TimeoutInterval, which is calculated from EstimatedRTT and DevRTT.
    - The second major event is the timeout. TCP responds to the timeout event by retransmitting the segment that caused the timeout. TCP then restarts the timer.
    - The third major event that must be handled by the TCP sender. 
      - On the occurrence of this event, TCP compares the ACK value y with its variable SendBase. 
      - The TCP state variable SendBase is the sequence number of the oldest unacknowledged byte. 

***

**A Few Interesting Scenarios**

***

**Flow Control**

>If the application is relatively slow at reading the data, the sender can very easily overflow the connection’s receive buffer by sending too much data too quickly.
>
>TCP provides a **flow-control service** to its applications to eliminate the possibility of the sender overflowing the receiver’s buffer. 
>
>Flow control is thus a speed-matching service—matching the rate at which the sender is sending against the rate at which the receiving application is reading.
>
>TCP provides flow control by having the sender maintain a variable called the **receive window**. 

- Define the following variables:
  - ***LastByteRead***: the number of the last byte in the data stream read from the buffer by the application process in B
  - ***LastByteRcvd***: the number of the last byte in the data stream that has arrived from the network and has been placed in the receive buffer at B
- The receive window, denoted rwnd is set to the amount of spare room in the buffer:
  `rwnd = RcvBuffer – [LastByteRcvd – LastByteRead]`

<img src=".\E}%M%`O3$Q8%OH2OFV4WWS.png" alt="img" style="zoom:50%;" />

- Host A in turn keeps track of two variables, ***LastByteSent*** and ***LastByteAcked***, which have obvious meanings. 

  - Note that the difference between these two variables, LastByteSent – LastByteAcked, is the amount of unacknowledged data that A has sent into the connection. 
  - By keeping the amount of unacknowledged data less than the value of rwnd, Host A is assured that it is not overflowing the receive buffer at Host B. 
  - Thus, Host A makes sure throughout the connection’s life that

  $$
  LastByteSent – LastByteAcked \le rwnd
  $$


***

#### TCP Conection Management

- The client application process first informs the client TCP that it wants to establish a connection to a process in the server. 

- The TCP in the client then proceeds to establish a TCP connection with the TCP in the server in the following manner:

  - ***Step 1.*** The client-side TCP first sends a special TCP segment to the server-side TCP. 

    - This special segment contains no application-layer data. But one of the flag bits in the segment’s header, the **SYN** bit, is set to 1. For this reason, this special segment is referred to as a SYN segment. 
    - In addition, the client randomly chooses an initial sequence number (client_isn) and puts this number in the sequence number field of the initial TCP SYN segment. 
    - There has been considerable interest in properly randomizing the choice of the client_isn in order to avoid certain security attacks **[CERT 2001–09]**.

  - ***Step 2.*** Once the IP datagram containing the TCP SYN segment arrives at the server host (assuming it does arrive!), the server extracts the TCP SYN segment from the datagram, allocates the TCP buffers and variables to the connection, and sends a connection-granted segment to the client TCP. 

    - This connection-granted segment also contains no application-layer data. However, it does contain three important pieces of information in the segment header. 
    - First, the SYN bit is set to 1. 
    - Second, the acknowledgment field of the TCP segment header is set to client_isn+1. 
    - Finally, the server chooses its own initial sequence number (server_isn) and puts this value in
      the sequence number field of the TCP segment header. 

    The connection-granted segment is referred to as a **SYNACK** segment.

  - ***Step 3.*** Upon receiving the SYNACK segment, the client also allocates buffers and variables to the connection. 

    - The client host then sends the server yet another segment; this last segment acknowledges the server’s connection-granted segment (the client does so by putting the value server_isn+1 in the acknowledgment field of the TCP segment header). 
    - The SYN bit is set to zero, since the connection is established. 
    - This third stage of the three-way handshake may carry client-to-server data in the segment payload.

  - Once these three steps have been completed, the client and server hosts can send segments containing data to each other. 

  - In each of these future segments, the **SYN** bit will be set to zero. 

***

**Close TCP Connection**

- As an example, suppose the client decides to close the connection, as shown in Figure 3.40. The client application process issues a close command. 
  - This causes the client TCP to send a special TCP segment to the server process. This special segment has a flag bit in the segment’s header, the FIN bit set to 1. 
  - When the server receives this segment, it sends the client an acknowledgment segment in return. 
  - The server then sends its own shutdown segment, which has the FIN bit set to 1. 
  - Finally, the client acknowledges the server’s shutdown segment. At this point, all the resources in the two hosts are now deallocated.

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\112.png" style="zoom: 33%;" />

<img src=".\21.png" style="zoom:50%;" />

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\22.png" style="zoom:50%;" />

> We have not described what happens in certain pathological scenarios, for example, when both sides of a connection want to initiate or shut down at the same time. 
>
> If you are interested in learning about this and other advanced issues concerning TCP, you are encouraged to see Stevens’ comprehensive book **[Stevens 1994]**.

>Nmap is a powerful tool, which can “case the joint” not only for open TCP ports, but also for open UDP ports, for firewalls and their configurations, and even for the versions of applications and operating systems. Most of this is done by manipulating TCP connection-management segments **[Skoudis 2006]**. You can download nmap from www.nmap.org.

***

### 3.6 Principles of Congestion Control

**Approaches to Congestion Control**

> At the broadest level, we can distinguish among congestion-control approaches by whether the network layer provides any explicit assistance to the transport layer for congestion-control purposes:

- ***End-to-end congestion control.*** In an end-to-end approach to congestion control, the network layer provides no explicit support to the transport layer for congestion- control purposes. 

- ***Network-assisted congestion control.*** With network-assisted congestion control, network-layer components (that is, routers) provide explicit feedback to the sender regarding the congestion state in the network. 
  - This feedback may be as simple as a single bit indicating congestion at a link. **[RFC 3168]**
  - More sophisticated network feedback is also possible. For example, one form of ATM ABR congestion control that we will study shortly allows a router to inform the sender explicitly of the ***transmission rate it (the router) can support*** on an outgoing link. 
  - The XCP protocol **[Katabi 2002]** provides router-computed feedback to each source, carried in the packet header, regarding how that source should increase or decrease its transmission rate.

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\image-20201124210707704.png" alt="image-20201124210707704" style="zoom:50%;" />

***

**Network-Assisted Congestion-Control Example: ATM ABR Congestion Control**

ATM: Asynchronous Transfer Mode

ABR:  available bit-rate 

>ABR has been designed as an elastic data transfer service in a manner reminiscent of TCP. 
>
>When the network is underloaded, ABR service should be able to take advantage of the spare available bandwidth; 
>
>When the network is congested, ABR service should throttle its transmission rate to some predetermined minimum transmission rate.
>
>A detailed tutorial on ATM ABR congestion control and traffic management is provided 
>
>in **[Jain 1996]**.

**resource-management cells**

<img src="C:\Users\13793\Desktop\学习笔记\计算机网络\image-20201124211853496.png" alt="image-20201124211853496" style="zoom:50%;" />

***

### 3.7 TCP Congestion Control

>TCP must use end-to-end congestion control rather than network-assisted congestion control, since the IP layer provides no explicit feedback to the end systems regarding network congestion.

`rwnd = RcvBuffer – [LastByteRcvd – LastByteRead] ` 

`cwnd = Congestion Window` 

> Let us henceforth assume that the TCP receive buffer is so large that the receive-window constraint can be ignored; 
>
> thus, the amount of unacknowledged data at the sender is solely limited by ***cwnd***. 

- The constraint above ***limits the amount of unacknowledged data*** at the sender and therefore indirectly limits the sender’s send rate. 
  - To see this, consider a connection for which loss and packet transmission delays are negligible. 
  - Then, roughly, at the beginning of every RTT, the constraint permits the sender to send cwnd bytes of data into the connection
  - At the end of the RTT the sender receives acknowledg- ments for the data. 
  - Thus the sender’s ***send rate*** is roughly ***cwnd/RTT*** bytes/sec. By adjusting the value of cwnd, the sender can therefore adjust the rate at which it sends data into its connection.

- Let us define a “loss event” at a TCP sender as the occurrence of either a timeout or the receipt of three duplicate ACKs from the receiver. 

**TCP congestion-control algorithm [RFC 5681]**

>The algorithm has three major components: ***slow start***, ***congestion avoidance*** and ***fast recovery.*** 

**Slow Start**

>When a TCP connection begins, the value of cwnd is typically initialized to a small value of 1 MSS **[RFC 3390]**, resulting in an initial sending rate of roughly MSS/RTT. 
>
>For example, if (maximum-sized segments) MSS= 500 bytes and RTT = 200 msec, the resulting initial sending rate is only about 20 kbps. 

- Thus, in the **slow-start** state, the value of cwnd begins at 1 MSS and increases by 1 MSS every time a transmitted segment is first acknowledged. 
- This process results in a doubling of the sending rate every RTT. 
- Thus, the TCP send rate starts slow but grows exponentially during the slow start phase.

![](C:\Users\13793\Desktop\学习笔记\计算机网络\a.png)

TCP SPLITTING: OPTIMIZING THE PERFORMANCE OF CLOUD SERVICES

[Pathak 2010] [Tariq 2008, Pathak 2010, Chen 2011] [Chen 2011]

**Congestion Avoidance**

>On entry to the congestion-avoidance state, the value of cwnd is approximately half its value when congestion was last encountered.
>
>TCP adopts a more conservative approach and increases the value of cwnd by just a single MSS every RTT.

**Fast Recovery**

>In fast recovery, the value of cwnd is increased by 1 MSS for every duplicate ACK received for the missing segment that caused TCP to enter the fast-recovery state.
>
>Eventually, when an ACK arrives for the missing segment, TCP enters the congestion-avoidance state after deflating cwnd. 

**TCP Congestion Control: Retrospective**

> TCP congestion control is often referred to as an **additive-increase, multiplicative- decrease** (**AIMD**) form of congestion control.

<img src=".\image-20201219144357009.png" alt="image-20201219144357009" style="zoom:50%;" />

- As noted previously, many TCP implementations use the Reno algorithm [**Padhye2001**]. 
- Many variations of the Reno algorithm have been proposed [**RFC 3782**; **RFC2018**]. 
- The TCP Vegas algorithm [**Brakmo 1995; Ahn 1995**] attempts to avoid congestion while maintaining good throughput. 
  - The basic idea of Vegas is to (1) detect congestion in the routers between source and destination before packet loss occurs
  - (2)lower the rate linearly when this imminent packet loss is detected. Imminent packet loss is predicted by observing the RTT. The longer the RTT of the packets, the greater the congestion in the routers. 

-  For a recent survey of the many flavors of TCP, see [**Afanasyev 2010**].

-  A rich theory of congestion control has since been developed [**Srikant 2004**].

***

**Macroscopic Description of TCP Throughput**



**TCP Over High-Bandwidth Paths**

>It is important to realize that TCP congestion control has evolved over the years and indeed continues to evolve. For a summary of current TCP variants and discussion of TCP evolution, see [**Floyd 2001**, **RFC 5681**, **Afanasyev 2010**]. 

**see [Jin 2004; RFC 3649; Kelly 2003; Ha 2008] for discussions of these efforts.**

***

**Fairness**

>Consider K TCP connections, each with a different end-to-end path, but all passing through a bottleneck link with transmission rate R bps. 
>
>Suppose each connection is transferring a large file and there is no UDP traffic passing through the bottleneck link. 
>
>A congestion-control mechanism is said to be fair if the average transmission rate of each connections  approximately R/K.

- **[Chiu 1989]** provides an elegant and intuitive explanation of why TCP congestion control converges to provide an equal share of a bottleneck link’s bandwidth among competing TCP connections.

<img src=".\123.png" style="zoom:50%;" />

**Fairness and UDP**

[**Floyd 1999; Floyd 2000; Kohler 2006**]

***

**Fairness and Parallel TCP Connections**

***

### 3.8 Summary

- The Datagram Congestion Control Protocol (DCCP) [**RFC 4340**] provides a low-overhead, message-oriented, UDP-like unreliable service, but with an application-selected form of congestion control that is compatible with TCP. 

- The Stream Control Transmission Protocol (SCTP) [**RFC 4960, RFC 3286**] is a reliable, message-oriented protocol that allows several different application-level “streams” to be multiplexed through a single SCTP connection (an approach known as “multi-streaming”). 

***

http://www.awl.com/kurose-ross

***

## 4. The Network Layer

### 4.1 Introduction

**Forwarding and Routing**

> The role of the network layer is thus deceptively simple—to move packets from a sending host to a receiving host.

- *Forwarding*. When a packet arrives at a router’s input link, the router must move the packet to the appropriate output link. 
- *Routing*. The network layer must determine the route or path taken by packets as they flow from a sender to a receiver. 

>Every router has a **forwarding table**. A router forwards a packet by examining the value of a field in the arriving packet’s header, and then using this header value to index into the router’s forwarding table. 

***

### 4.2 Virtual Circuit and Datagram Networks

>Computer networks that provide only a ***connection service*** at the network layer are called ***virtual-circuit*** ***(VC) networks***; 
>
>computer networks that provide only a ***connectionless service*** at the network layer are called ***datagram networks***.

**Virtual-Circuit Networks**

- A **VC** consists of 
  - a **path** (that is, a series of links and routers) between the source and destination hosts
  - **VC numbers**, one number for each link along the path
  - entries in the forwarding table in each router along the path.

- Why a packet doesn’t just keep the same VC number on each of the links along its route. The answer is twofold. 
  - First, replacing the number from link to link ***reduces the length of the VC field*** in the packet header.
  - Second, and more importantly, VC setup is considerably simplified by permitting a different VC number at each link along the path of the VC. 

- In a VC network, the network’s routers must maintain **connection state information** for the ongoing connections.
  - each time a new connection is established across a router, a new connection entry must be added to the router’s forwarding table; 
  - and each time a connection is released, an entry must be removed from the table.

![image-20210224091149907](.\image-20210224091149907.png)

***

**Datagram Networks**

>In a datagram network, each time an end system wants to send a packet, it ***stamps*** the packet with ***the address of the destination end system*** and then pops the packet into the network. 
>
>There is no VC setup and routers do not maintain any VC state information. 

***

**Origins of VC and Datagram Networks**

***

### 4.3 What’s Inside a Router?

- A high-level view of a generic router architecture is shown in Figure 4.6. Four router components can be identified:

<img src=".\image-20210224093438412.png" alt="image-20210224093438412" style="zoom:50%;" />

- **Input ports**.	
  - terminating an incoming physical link at a router.
  - the ***lookup function*** is also performed at the input port; this will occur in the rightmost box of the input port.

- **Switching fabric**. 
  - The switching fabric connects the router’s input ports to its output ports.

- **Output ports.**
  - An output port stores packets received from the switching fabric and transmits these packets on the outgoing link by performing the necessary link-layer and physical-layer functions. 

- **Routing processor.** 
  - The routing processor executes the routing protocols, maintains routing tables and attached link state information, and computes the forwarding table for the router. 

***

**Input Processing**

>surveys of fast lookup algorithms can be found in **[Gupta 2001, Ruiz-Sanchez 2001]**. 

**Switching**

**Output Processing**

***

### 4.4 The Internet Protocol (IP): Forwarding and Addressing in the Internet

**Datagram Format**

<img src=".\image-20210228090655334.png" alt="image-20210228090655334" style="zoom:50%;" />

- The key fields in the IPv4 datagram are the following:

  - **Version number**. 
    - These 4 bits specify the IP protocol version of the datagram. By looking at the version number, the router can determine how to interpret the remainder of the IP datagram. 
  - **Header length.** 
    - Because an IPv4 datagram can contain a variable number of options (which are included in the IPv4 datagram header), these 4 bits are needed to determine where in the IP datagram the data actually begins. 
    - The typical IP datagram has a 20-byte header.

  - **Type of service.** 
    - The type of service (**TOS**) bits were included in the IPv4 header to allow different types of IP datagrams (for example, datagrams particularly requiring low delay, high throughput, or reliability) to be distinguished from each other. 
  - **Datagram length.** 
    - This is the total length of the IP datagram (header plus data), measured in bytes. 
  - **Identifier, flags, fragmentation offset.** 
    - These three fields have to do with so-called IP fragmentation, a topic we will consider in depth shortly. 
  - **Time-to-live.** 
    - The time-to-live (TTL) field is included to ensure that datagrams do not circulate forever in the network. This field is decremented by one each time the datagram is processed by a router. 
  - **Protocol.** 
    - This field is used only when an IP datagram reaches its *final destination*. 
    - The value of this field indicates the specific transport-layer protocol to which the data portion of this IP datagram should be passed. 
    - For example, a value of 6 indicates that the data portion is passed to TCP, while a value of 17 indicates that the data is passed to UDP. 
  - **Header checksum.** 
    - The header checksum aids a router in detecting bit errors in a received IP datagram. 
    - An interesting discussion of fast algorithms for computing the Internet checksum is [**RFC 1071**].
  - **Source and destination IP addresses.** 
    - When a source creates a datagram, it inserts its IP address into the source IP address field and inserts the address of the ultimate destination into the destination IP address field.
  - **Options.** 
    - The options fields allow an IP header to be extended.
  - **Data (payload).**
    - In most circumstances, the data field of the IP datagram contains the transport-layer segment (TCP or UDP) to be delivered to the destination. However, the data field can carry other types of data, such as ICMP messages.

***

**IP Datagram Fragmentation**

>The maximum amount of data that a link-layer frame can carry is called the **maximum transmission unit (MTU)**.
>
>What is a problem is that each of the links along the route between sender and destination can use different link-layer protocols, and each of these protocols can have different MTUs.

- A router receives an IP datagram from one link. You check your forwarding table to determine the outgoing link, and this outgoing link has an MTU that is ***smaller*** than the length of the IP datagram. 

- The solution is to fragment the data in the IP datagram into two or more smaller IP datagrams. Each of these smaller datagrams is referred to as a **fragment**.

- Fragments need to be reassembled before they reach the transport layer at the destination. 
  - Sticking to the principle of keeping the network core simple, the designers of IPv4 decided to put the job of datagram reassembly in the ***end systems*** rather than in network routers.
  - To allow the destination host to perform these reassembly tasks, the designers of IP (version 4) put identification, flag, and fragmentation offset fields in the IP datagram header.
  - Because IP is an unreliable service, one or more of the fragments may never arrive at the destination. in order for the destination host to be absolutely sure it has received the last fragment of the original datagram, ***the last fragment has a flag bit set to 0***, whereas all the other fragments have this flag bit set to 1. 
  - In order for the destination host to determine whether a fragment is missing (and also to be able to reassemble the fragments in their proper order), the offset field is used to ***specify where the fragment fits*** within the original IP datagram.

***

**IPv4 Addressing**

>Excellent treatments of IPv4 addressing are [3Com Addressing 2012] and the first chapter in [Stewart 1999].

- To determine the **subnets**, detach each interface from its host or router, creating islands of isolated networks, with interfaces terminating the end points of the isolated networks. Each of these isolated networks is called a subnet.

- The Internet’s address assignment strategy is known as **Classless Interdomain Routing** (CIDR—pronounced cider) **[RFC 4632]**.

**Obtaining a Block of Addresses**

> In order to obtain a block of IP addresses for use within an organization’s subnet, a network administrator might first contact its ISP, which would provide addresses from a larger block of addresses that had already been allocated to the ISP. 

#### **Obtaining a Host Address: DH**CP

>Host addresses can be configured manually, but more often this task is now done using the **Dynamic Host Configuration Protocol (DHCP)** [**RFC 2131**].

- For a newly arriving host, the DHCP protocol is a four-step process:
  - ***DHCP server discovery***. 
    - The first task of a newly arriving host is to find a DHCP server with which to interact. This is done using a **DHCP discover message**, which a client sends within a ***UDP packet*** to port **67**. The UDP packet is encapsulated in an IP datagram. 
    - The DHCP client creates an IP datagram containing its DHCP discover message along with the broadcast destination IP address of 255.255.255.255 and a “this host” source IP address of 0.0.0.0.
    - The DHCP client passes the IP datagram to the link layer, which then broadcasts this frame to all nodes attached to the subnet.
  - ***DHCP server offer(s).*** 
    - A DHCP server receiving a DHCP discover message responds to the client with a **DHCP offer message** that is broadcast to all nodes on the subnet, again using the IP broadcast address of 255.255.255.255.
    - Server offers message contains the **transaction ID** of the received discover message, the proposed **IP address** for the client, the **network mask**, and an IP **address lease time**—the amount of time for which the IP address will be valid.
  - ***DHCP request.*** 
    - The newly arriving client will choose from among one or more server offers and respond to its selected offer with a **DHCP request message**, echoing back the configuration parameters.
  - ***DHCP ACK.*** 
    - The server responds to the DHCP request message with a **DHCP ACK message**, confirming the requested parameters.

***

**Network Address Translation (NAT)**

> **[RFC 2663; RFC 3022; Zhang 2007]**

>The NAT router behaves to the outside world as a single device with a single IP address.

<img src=".\image-20210301211344629.png" alt="image-20210301211344629" style="zoom:50%;" />

- In Figure 4.22, all traffic leaving the home router for the larger Internet has a source IP address of 138.76.29.7, and all traffic entering the home router must have a destination address of 138.76.29.7.

***

**Internet Control Message Protocol (ICMP)**

>ICMP, specified in **[RFC 792]**, is used by hosts and routers to communicate network-layer information to each other. 
>
>The most typical use of ICMP is for error reporting.

<img src=".\image-20210301215118689.png" alt="image-20210301215118689" style="zoom:50%;" />

***

**IPv6**

>The result of this effort was the specification of IP version 6 (IPv6) **[RFC 2460]** which we’ll discuss below. 
>
>Excellent sources of information about IPv6 are [Huitema 1998, IPv6 2012].

**IPv6 Datagram Format**

- The most important changes introduced in IPv6 are evident in the datagram format:

<img src=".\image-20210301220346050.png" alt="image-20210301220346050" style="zoom:50%;" />

- ***Expanded addressing capabilities***. 
  - IPv6 increases the size of the IP address from 32 to 128 bits. 
  - In addition to unicast and multicast addresses, IPv6 has introduced a new type of address, called an anycast address, which allows a datagram to be delivered to any one of a group of hosts.
- ***A streamlined 40-byte header.*** 
  - As discussed below, a number of IPv4 fields have been dropped or made optional. The resulting 40-byte fixed-length header allows for faster processing of the IP datagram. A new encoding of options allows for more flexible options processing.

- ***Flow labeling and priority.*** 
  - IPv6 has an elusive definition of a flow.

- **Version.** 
  - This 4-bit field identifies the IP version number. Not surprisingly, IPv6 carries a value of 6 in this field. Note that putting a 4 in this field does not create a valid IPv4 datagram.

- **Traffic class.** 
  - This 8-bit field is similar in spirit to the TOS field we saw in IPv4.

- **Payload length.** 
  - This 16-bit value is treated as an unsigned integer giving the number of bytes in the IPv6 datagram following the fixed-length, 40-byte datagram header.
- **Next header.** 
  - This field identifies the protocol to which the contents (data field) of this datagram will be delivered 

- **Hop limit.** 
  - The contents of this field are decremented by one by each router that forwards the datagram. If the hop limit count reaches zero, the datagram is discarded.

****

**Transitioning from IPv4 to IPv6**

***

### 4.5 Routing Algorithms

> Typically a host is attached directly to one router, the default router for the host (also called the first-hop router for the host). 
>
> We refer to the default router of the source host as the **source router** and the default router of the destination host as the **destination router**.

- A **global routing algorithm** computes the least-cost path between a source and destination using complete, global knowledge about the network.

- In a **decentralized routing algorithm**, the calculation of the least-cost path is carried out in an iterative, distributed manner. 

**The Link-State (LS) Routing Algorithm**



















***

### 5.4 Switched Local Area Network

>Instead of using IP addresses, we will soon see that they use link-layer addresses to forward link-layer frames through the network of switches. 

**Link-Layer Addressing and ARP**

**MAC Addresses**

> In truth, it is not hosts and routers that have link-layer addresses but rather their **adapters** (that is, network interfaces) that have link-layer addresses. 

- A host or router with multiple network interfaces will thus have multiple link-layer addresses associated with it, just as it would also have multiple IP addresses associated with it.
- It's important to note, however, that **link-layer switche**s do not have link-layer addresses associated with their interfaces that connect to hosts and routers.

>  A link-layer address is variously called a LAN address, a physical address, or a **MAC address**. 

- the MAC address is 6 bytes long, giving 2^48^ possible MAC addresses. 
  - these 6-byte addresses are typically expressed in hexadecimal nota- tion, with each byte of the address expressed as a pair of hexadecimal numbers.

  `88-B2-2F-54-1A-0F`

***

**Address Resolution Protocol (ARP)**

>Because there are both network-layer addresses (for example, Internet IP addresses) and link-layer addresses (that is, MAC addresses), there is a need to translate between them. For the Internet, this is the job of the Address Resolution Protocol (**ARP**) [**RFC 826**].

- An ARP module in the sending host takes any IP address on the same LAN as input, and returns the corresponding MAC address.

- One important difference between the two resolvers is that DNS resolves host names for hosts anywhere in the Internet, whereas **ARP resolves IP addresses** only for hosts and router interfaces **on the same subnet**.

- The ARP table also contains a **time-to-live (TTL)** value, which indicates when each mapping will be deleted from the table. 
  - Note that a table does not necessarily contain an entry for every host and router on the subnet; 
  - some may have never been entered into the table, and others may have expired.
  - A typical expiration time for an entry is 20 minutes from when an entry is placed in an ARP table.

- What if the ARP table doesn’t currently have an entry for the destination? 
  - First, the sender constructs a special packet called an **ARP packet**. An ARP packet has several fields, including the sending and receiving IP and MAC addresses. 
    - Both ARP query and response packets have the same format. 
    - The purpose of the ARP query packet is to **query all the other hosts and routers** on the subnet to determine the MAC address corresponding to the IP address that is being resolved.
  - 222.222.222.220 passes an ARP query packet to the adapter along with an indication that the adapter should send the packet to the **MAC broadcast address**,  FF-FF-FF-FF-FF-FF.
  - The adapter encapsulates the ARP packet in a link-layer frame, uses the broadcast address for the frame’s destination address, and transmits the frame into the subnet. 
  - The frame containing the ARP query is received by all the other adapters on the subnet, and (because of the broadcast address) each adapter passes the ARP packet within the frame up to its ARP module. 
  - Each of these ARP modules checks to see if its IP address **matches** the destination IP address in the ARP packet. 
  - The one with a match **sends back to the querying host a response ARP packet** with the desired mapping.
  - The querying host 222.222.222.220 can then update its ARP table and send its IP datagram.

***

**Sending a Datagram off the Subnet**

A nice introduction to ARP is given in the TCP/IP tutorial, **RFC 1180**. 

***

**Ethernet Frame Structure**

![image-20210326085440439](C:\Users\13793\Desktop\学习笔记\计算机网络\image-20210326085440439.png)

- **Data field** (46 to 1,500 bytes). This field carries the IP datagram. The maximum transmission unit (MTU) of Ethernet is 1,500 bytes. 

- **Destination address** (6 bytes). This field contains the MAC address of the destination adapter, BB-BB-BB-BB-BB-BB. 
- **Source address** (6 bytes). This field contains the MAC address of the adapter that transmits the frame onto the LAN.
- **Type field** (2 bytes). The type field permits Ethernet to multiplex network-layer protocols. 

- **Cyclic redundancy check** (CRC) (4 bytes). The purpose of the CRC field is to allow the receiving adapter, adapter B, to detect bit errors in the frame.
- **Preamble** (8 bytes). The Ethernet frame begins with an 8-byte preamble field.
  - Each of the first 7 bytes of the preamble has a value of 10101010; the last byte is 10101011. 
  - The first 7 bytes of the preamble serve to “wake up” the receiving adapters and to synchronize their clocks to that of the sender’s clock.

***

### 5.7.1 Getting Started: DHCP, UDP, IP, and Ethernet

>The school’s router is connected to an ISP, in this example, **comcast.net**. In this example, comcast.net is providing the DNS service for the school; thus, the DNS server resides in the Comcast network rather than the school network. 

- When Bob first connects his laptop to the network, he can’t do anything (e.g., download a Web page) without an IP address. 

- Thus, the first network-related action taken by Bob’s laptop is to run the DHCP protocol to obtain an IP address, as well as other information, from the local DHCP server:

  - The operating system on Bob’s laptop creates a **DHCP request message** (Section 4.4.2) and puts this message within a **UDP segment** (Section 3.3) with destination **port 67** (DHCP server) and source **port 68** (DHCP client). 
    - The UDP segment is then placed within an IP datagram (Section 4.4.1) with a broadcast IP destination address (255.255.255.255) and a source IP address of 0.0.0.0, since Bob’s laptop doesn’t yet have an IP address.
  - The IP datagram containing the DHCP request message is then placed within an **Ethernet frame** (Section 5.4.2). The Ethernet frame has a destination MAC addresses of FF:FF:FF:FF:FF:FF so that the frame will be broadcast to all devices connected to the switch (hopefully including a DHCP server); the frame’s source MAC address is that of Bob’s laptop, 00:16:D3:23:68:8A.
  - The broadcast Ethernet frame containing the DHCP request is the first frame sent by Bob’s laptop to the Ethernet switch. The switch broadcasts the incoming frame on all outgoing ports, including the port connected to the router.
  - The router receives the broadcast Ethernet frame containing the DHCP request on its interface with MAC address 00:22:6B:45:1F:1B and the IP datagram is extracted from the Ethernet frame. 
    - The datagram’s broadcast IP destination address indicates that this IP datagram should be processed by upper layer protocols at this node, so the datagram’s payload (a UDP segment) is thus **demultiplexed** (Section 3.2) up to UDP, and the DHCP request message is extracted from the UDP segment. The DHCP server now has the DHCP request message.

  - Let’s suppose that the DHCP server running within the router can allocate IP addresses in the **CIDR** (Section 4.4.2) block 68.85.2.0/24. In this example, all IP addresses used within the school are thus within Comcast’s address block.
  - Let’s suppose the DHCP server allocates address 68.85.2.101 to Bob’s laptop. The DHCP server creates a **DHCP ACK** message (Section 4.4.2) containing this IP address, as well as the IP address of the **DNS server** (68.87.71.226), the IP address for the **default gateway router** (68.85.2.1), and the **subnet block** (68.85.2.0/24) (equivalently, the “network mask”). 
    - The DHCP message is put inside a UDP segment, which is put inside an IP datagram, which is put inside an Ethernet frame. The Ethernet frame has a source MAC address of the router’s interface to the home network (00:22:6B:45:1F:1B) and a destination MAC address of Bob’s laptop (00:16:D3:23:68:8A).
  - The Ethernet frame containing the DHCP ACK is sent (unicast) by the router to the switch. Because the switch is **self**-**learning** (Section 5.4.3) and previously received an Ethernet frame (containing the DHCP request) from Bob’s laptop, the switch knows to forward a frame addressed to 00:16:D3:23:68:8A only to the output port leading to Bob’s laptop.
  - Bob’s laptop receives the Ethernet frame containing the DHCP ACK, extracts the IP datagram from the Ethernet frame, extracts the UDP segment from the IP datagram, and extracts the DHCP ACK message from the UDP segment. 
    - Bob’s DHCP client then records its IP address and the IP address of its DNS server. It also installs the address of the default gateway into its **IP forwarding table** (Section 4.1). Bob’s laptop will send all datagrams with destination address outside of its subnet 68.85.2.0/24 to the default gateway. 

![image-20210324145543933](C:\Users\13793\Desktop\学习笔记\计算机网络\image-20210324145543933.png)

***

### 5.7.2 Still Getting Started: DNS and ARP

> When Bob types the URL for www.google.com into his Web browser, he begins the long chain of events that will eventually result in Google’s home page being displayed by his Web browser. 

- The operating system on Bob’s laptop thus creates a DNS query message (Section2.5.3), putting the string “www.google.com” in the question section of the DNS message. This DNS message is then placed within a UDP segment with a destination port of 53 (DNS server). The UDP segment is then placed within an IP datagram with an IP destination address of 68.87.71.226 (the address of the DNS server returned in the DHCPACK in step 5) and a source IP address of 68.85.2.101.

- Bob’s laptop then places the datagram containing the DNS query message in an Ethernet frame. This frame will be sent (addressed, at the link layer) to the gateway router in Bob’s school’s network. 
  - However, even though Bob’s laptop knows the IP address of the school’s gateway router (68.85.2.1) via the DHCP ACK message in step 5 above, it doesn’t know the gateway router’s MAC address. In order to obtain the MAC address of the gateway router, Bob’s laptop will need to use the **ARP** protocol (Section 5.4.1).
- Bob’s laptop creates an ARP query message with a target IP address of 68.85.2.1 (the default gateway), places the ARP message within an Ethernet frame with a broadcast destination address (FF:FF:FF:FF:FF:FF) and sends the Ethernet frame to the switch, which delivers the frame to all connected devices, including the gateway router.

- The gateway router receives the frame containing the ARP query message on the interface to the school network, and finds that the target IP address of 68.85.2.1 in the ARP message matches the IP address of its interface. The gateway router thus prepares an ARP reply, indicating that its MAC address of 00:22:6B:45:1F:1B corresponds to IP address 68.85.2.1. 
- Bob’s laptop receives the frame containing the ARP reply message and extracts the MAC address of the gateway router (00:22:6B:45:1F:1B) from the ARP reply message.

- Bob’s laptop can now ( finally!) address the Ethernet frame containing the DNS query to the gateway router’s MAC address. Note that the IP datagram in this frame has an IP destination address of 68.87.71.226 (the DNS server), while the frame has a destination address of 00:22:6B:45:1F:1B (the gateway router). Bob’s laptop sends this frame to the switch, which delivers the frame to the gateway router.

***

### 5.7.3 Still Getting Started: Intra-Domain Routing to the DNS Server

14. The gateway router receives the frame and extracts the IP datagram containingthe DNS query. The router looks up the destination address of this datagram (68.87.71.226) and determines from its forwarding table that the datagram should be sent to the leftmost router in the Comcast network in Figure 5.32. 
    - The IP datagram is placed inside a link-layer frame appropriate for the link connecting the school’s router to the leftmost Comcast router and the frame is sent over this link.
15. The leftmost router in the Comcast network receives the frame, extracts the IP datagram, examines the datagram’s destination address (68.87.71.226) and determines the outgoing interface on which to forward the datagram towards the DNS server from its forwarding table, which has been filled in by Comcast’s intra-domain protocol (such as RIP, OSPF or IS-IS, Section 4.6) as well as the **Internet’s inter-domain protocol, BGP**.
16. Eventually the IP datagram containing the DNS query arrives at the DNS server. The DNS server extracts the DNS query message, looks up the name www.google.com in its DNS database (Section 2.5), and finds the DNS resource THE LINK LAYER: LINKS, ACCESS NETWORKS, AND LANS record that contains the IP address (64.233.169.105) for www.google.com. (assuming that it is currently cached in the DNS server). Recall that this cached data originated in the authoritative DNS server (Section 2.5.2) for googlecom. The DNS server forms a DNS reply message containing this hostname-to-IP-address mapping, and places the DNS reply message in a UDP segment, and the segment within an IP datagram addressed to Bob’s laptop (68.85.2.101). This datagram will be forwarded back through the Comcast network to the school’s router and from there, via the Ethernet switch to Bob’s laptop.
17. Bob’s laptop extracts the IP address of the server www.google.com from the DNS message. Finally, after a lot of work, Bob’s laptop is now ready to contact the www.google.com server!

***

### 5.7.4 Web Client-Server Interaction: TCP and HTTP

18. Now that Bob’s laptop has the IP address of www.google.com, it can create the TCP socket (Section 2.7) that will be used to send the HTTP GET message (Section 2.2.3) to www.google.com. When Bob creates the TCP socket, the TCP in Bob’s laptop must first perform a three-way handshake (Section 3.5.6) with the TCP in www.google.com. Bob’s laptop thus first creates a TCP SYN segment with destination port 80 (for HTTP), places the TCP segment inside an IP data-
gram with a destination IP address of 64.233.169.105 (www.google.com), places the datagram inside a frame with a destination MAC address of 00:22:6B:45:1F:1B (the gateway router) and sends the frame to the switch.
19. The routers in the school network, Comcast’s network, and Google’s network forward the datagram containing the TCP SYN towards www.google.com, using the forwarding table in each router, as in steps 14–16 above. Recall that the router forwarding table entries governing forwarding of packets over the inter-domain link between the Comcast and Google networks are determined by the BGP protocol (Section 4.6.3).
20. Eventually, the datagram containing the TCP SYN arrives at www.google.com. The TCP SYN message is extracted from the datagram and demultiplexed to the welcome socket associated with port 80. A connection socket (Section 2.7) is created for the TCP connection between the Google HTTP server and Bob’s laptop. A TCP SYNACK (Section 3.5.6) segment is generated, placed inside a datagram addressed to Bob’s laptop, and finally placed inside a link-layer frame
appropriate for the link connecting www.google.com to its first-hop router.
21. The datagram containing the TCP SYNACK segment is forwarded through the Google, Comcast, and school networks, eventually arriving at the Ethernet card in Bob’s laptop. The datagram is demultiplexed within the operating system to the TCP socket created in step 18, which enters the connected state.
22. With the socket on Bob’s laptop now (finally!) ready to send bytes to www.google.com, Bob’s browser creates the HTTP GET message (Section 2.2.3) containing the URL to be fetched. The HTTPGET message is then written into the socket, with the GET message becoming the payload of a TCP segment. The TCP segment is placed in a datagram and sent and delivered to www.google.com as in steps 18–20 above.
23. The HTTP server at www.google.com reads the HTTP GET message from the TCP socket, creates an HTTP response message (Section 2.2), places the requested Web page content in the body of the HTTP response message, and sends the message into the TCP socket.
24. The datagram containing the HTTP reply message is forwarded through the Google, Comcast, and school networks, and arrives at Bob’s laptop. Bob’s Web browser program reads the HTTP response from the socket, extracts the html for the Web page from the body of the HTTP response, and finally ( finally!) displays the Web page!